{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import numpy as np\n",
    "from keras.layers import LSTM,Dense,Embedding,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils \n",
    "from music21 import converter,instrument,note,chord,stream\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq(notes,n_vocab,pitchname):\n",
    "    length=50\n",
    "    #mapping each node to int\n",
    "    note_to_int=dict((note,number) for number,note in enumerate(pitchname))\n",
    "    input_seq=[]\n",
    "    output_seq=[]\n",
    "    for i in range(0,len(notes)-length,1):\n",
    "        in_seq=notes[i:i+length]\n",
    "        out_seq=notes[i+length]\n",
    "        input_seq.append([note_to_int[char] for char in in_seq])\n",
    "        output_seq.append(note_to_int[out_seq])\n",
    "    n_pattern=len(input_seq)\n",
    "    \n",
    "    #reshaping the input to amke it compatible with lstm\n",
    "    input_seq_normalized=np.reshape(input_seq,(n_pattern,length,1))\n",
    "    #normalizing\n",
    "    input_seq_normalized=input_seq_normalized/float(n_vocab)\n",
    "    return (input_seq,input_seq_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(input_seq,n_vocab):\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(256,input_shape=(input_seq.shape[1],input_seq.shape[2]),return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512,return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(256))\n",
    "    model.add(Dense(256,activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab,activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"rmsprop\")\n",
    "    model.load_weights(\"weights.hdf5\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_using_model(input_seq,n_vocab,model,pitchname):\n",
    "    # now we want our model to predict the music using given input seq \n",
    "    # we will use input sequence from file we save in training process hence to access the file randomly we use \n",
    "    #random variable available in numpy\n",
    "    start=np.random.randint(1,len(input_seq)-1)\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "    pattern=input_seq[start]\n",
    "    pred_seq=[]\n",
    "    #we will generate 500 o/p which will give music of about 2 minutes\n",
    "    for note_index in range(600):\n",
    "        predicted_input=np.reshape(pattern,(1,len(pattern),1))\n",
    "        predicted_input=predicted_input/float(n_vocab)   #normalization\n",
    "        prediction=model.predict(predicted_input,verbose=0)\n",
    "        index=np.argmax(prediction)\n",
    "        result=int_to_note[index]\n",
    "        pred_seq.append(result)\n",
    "        \n",
    "        pattern.append(index)\n",
    "        pattern=pattern[1:len(pattern)]\n",
    "    return pred_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi_file(pred_seq):\n",
    "    offset=0\n",
    "    output_seq=[]\n",
    "    for pattern in pred_seq:\n",
    "        if (\".\" in pattern) or pattern.isdigit():\n",
    "            notes_in_chord=pattern.split(\".\")\n",
    "            notes=[]\n",
    "            for current_notes in notes_in_chord:\n",
    "                new_note=note.Note(int(current_notes))\n",
    "                new_note.storedInstrument=instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord=chord.Chord(notes)\n",
    "            new_chord.offset=offset\n",
    "            output_seq.append(new_chord)\n",
    "        else:\n",
    "            new_note=note.Note(pattern)\n",
    "            new_note.offset=offset\n",
    "            new_note.storedInstrument=instrument.Piano()\n",
    "            output_seq.append(new_note)\n",
    "        offset=offset+0.5\n",
    "    midi_stream=stream.Stream(output_seq)\n",
    "    midi_stream.write(\"midi\",fp=\"output_music.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create_midi_file\n",
    "\n",
    "Now that we have all the encoded representations of the notes and chords in an array we can start decoding them and creating an array of Note and Chord objects.\n",
    "\n",
    "First we have to determine whether the output we are decoding is a Note or a Chord.\n",
    "\n",
    "If the pattern is a Chord, we have to split the string up into an array of notes. Then we loop through the string representation of each note and create a Note object for each of them. Then we can create a Chord object containing each of these notes.\n",
    "\n",
    "\n",
    "If the pattern is a Note, we create a Note object using the string representation of the pitch contained in the pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"notes\",\"rb\") as filepath:\n",
    "    notes=pickle.load(filepath)\n",
    "pitchnames=sorted(set(pitch for pitch in notes))\n",
    "n_vocab=len(set(notes))\n",
    "network_input, normalized_input = create_seq(notes, n_vocab, pitchnames)\n",
    "model = load_model(normalized_input, n_vocab)\n",
    "prediction_output = predict_using_model(network_input,n_vocab,model,pitchnames)\n",
    "create_midi_file(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
